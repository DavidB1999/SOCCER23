{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e50add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from statistics import mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Pickles/AllDatapoints_e100.pkl', 'rb') as f:\n",
    "    full_data = pickle.load(f)\n",
    "with open('Pickles/Datasets.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6580fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "games_included = []\n",
    "\n",
    "game_data = (r'SUCCESS_SCORES')\n",
    "\n",
    "for dirMD in os.listdir(game_data):\n",
    "        locMD = os.path.join(game_data, dirMD)\n",
    "        for dirM in os.listdir(locMD):\n",
    "            games_included.append(dirM)\n",
    "            \n",
    "with open('Games_Included.pkl', 'wb') as l:\n",
    "    pickle.dump(games_included, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bdfe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "GO = pd.read_csv('Output/GameOverview3.csv', index_col=0)\n",
    "GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = GO.Home.unique()\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9812ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_to_games = {}\n",
    "\n",
    "for team in teams:\n",
    "    game_list = GO.MI_Name.loc[(GO.Home == team) | (GO.Away == team)].to_list() \n",
    "    team_to_games[team] =  []\n",
    "\n",
    "    for game in game_list:\n",
    "        if game in games_included: # only the games were data is included!\n",
    "            team_to_games[team].append(game)  \n",
    "\n",
    "team_to_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a08025",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = GO.MI_Name.unique()\n",
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_to_teams = {}\n",
    "\n",
    "for game in games_included:   # only the games where i have data\n",
    "    game_to_teams[game] = [GO['Home'].loc[GO.MI_Name == game].to_list()[0],GO['Away'].loc[GO.MI_Name == game].to_list()[0]] \n",
    "    \n",
    "game_to_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect success scores for each team in each dataset\n",
    "team_data = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    team_data[dataset] = {}\n",
    "    for team in teams:\n",
    "        team_data[dataset][team] = []\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for frame in full_data[dataset]:\n",
    "        # extract match \n",
    "        match = frame[2][5:19]\n",
    "        if frame[1] == -3:\n",
    "            team_data[dataset][game_to_teams[match][0]].append(frame)\n",
    "        elif frame[1] == -1:\n",
    "            team_data[dataset][game_to_teams[match][1]].append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data.keys()\n",
    "for key in team_data.keys():\n",
    "    summ = 0\n",
    "    for team in teams:\n",
    "        #print(len(team_data[key][team]))\n",
    "        summ = summ + len(team_data[key][team])\n",
    "    print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/TeamData_e100.pkl', 'wb') as cdict:\n",
    "    pickle.dump(team_data, cdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the success scores for each team in each dataset\n",
    "team_Success_Scores = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    team_Success_Scores[dataset] = {}\n",
    "    for team in teams:\n",
    "        team_Success_Scores[dataset][team] = []\n",
    "        for frame in team_data[dataset][team]:\n",
    "            team_Success_Scores[dataset][team].append(frame[0])\n",
    "            \n",
    "for key in team_Success_Scores.keys():\n",
    "    summ = 0\n",
    "    for team in teams:\n",
    "        #print(len(team_data[key][team]))\n",
    "        summ = summ + len(team_Success_Scores[key][team])\n",
    "    print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae333cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/team_Success_Scores_e100.pkl', 'wb') as cdict:\n",
    "    pickle.dump(team_Success_Scores, cdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall average success score per team per dataset\n",
    "team_Success_Score_av = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    team_Success_Score_av[dataset] = {}\n",
    "    for team in teams:\n",
    "        team_Success_Score_av[dataset][team] = mean(team_Success_Scores[dataset][team])\n",
    "        \n",
    "team_Success_Score_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/Team_Success_Score_av_e100.pkl', 'wb') as cdict:\n",
    "    pickle.dump(team_Success_Score_av, cdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for each match of each team in each dataset\n",
    "team_game_data = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    team_game_data[dataset] = {}\n",
    "    for team in teams:\n",
    "        team_game_data[dataset][team] = {}\n",
    "        for match in team_to_games[team]:\n",
    "            team_game_data[dataset][team][match] = []\n",
    "            for frame in team_data[dataset][team]:\n",
    "                if match in frame[2]:\n",
    "                    team_game_data[dataset][team][match].append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b607b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_game_data['16m_100s']['FC Bayern München']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/team_game_data_e100.pkl', 'wb') as cdict:\n",
    "    pickle.dump(team_game_data, cdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae09ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# success for each match of each team in each dataset\n",
    "team_Success_Score_game = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    team_Success_Score_game[dataset] = {}\n",
    "    for team in teams:\n",
    "        team_Success_Score_game[dataset][team] = {}\n",
    "        for match in team_to_games[team]:\n",
    "            team_Success_Score_game[dataset][team][match] = []\n",
    "            for frame in team_game_data[dataset][team][match]:\n",
    "                team_Success_Score_game[dataset][team][match].append(frame[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_Success_Score_game['16m_100s']['1. FSV Mainz 05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66af7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/team_Success_Score_game_e100.pkl', 'wb') as cdict:\n",
    "    pickle.dump(team_Success_Score_game, cdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_Success_Score_game_av = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    team_Success_Score_game_av[dataset] = {}\n",
    "    for team in teams:\n",
    "        team_Success_Score_game_av[dataset][team] = {}\n",
    "        for match in team_to_games[team]:\n",
    "            team_Success_Score_game_av[dataset][team][match] = mean(team_Success_Score_game[dataset][team][match])\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_Success_Score_game_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/team_Success_Score_game_av_e100.pkl', 'wb') as cdict:\n",
    "    pickle.dump(team_Success_Score_game_av, cdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb697f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quality_dict = {}\n",
    "Quality_dict['Points'] = {\n",
    "    'FC Bayern München' : 82, \n",
    "    'SV Werder Bremen' : 45,\n",
    "    'Borussia Dortmund' : 64,\n",
    "    '1. FSV Mainz 05': 67,\n",
    "    'Borussia Mönchengladbach' : 45,\n",
    "    'Bayer 04 Leverkusen' : 41,\n",
    "    'Hertha BSC' : 49,\n",
    "    'Sport-Club Freiburg' : 48,\n",
    "    '1. FC Köln' : 49,\n",
    "    'SV Darmstadt 98' : 25,\n",
    "    'Hamburger SV' : 38,\n",
    "    'FC Ingolstadt 04' : 32,\n",
    "    'FC Augsburg' : 38,\n",
    "    'VfL Wolfsburg' : 37,\n",
    "    'TSG 1899 Hoffenheim' : 62,\n",
    "    'RB Leipzig' : 67,\n",
    "    'FC Schalke 04' : 43,\n",
    "    'Eintracht Frankfurt' : 42 \n",
    "}\n",
    "Quality_dict['Ranking'] = {\n",
    "    'FC Bayern München' : 1, \n",
    "    'SV Werder Bremen' : 8,\n",
    "    'Borussia Dortmund' : 3,\n",
    "    '1. FSV Mainz 05': 15,\n",
    "    'Borussia Mönchengladbach' : 9,\n",
    "    'Bayer 04 Leverkusen' : 12,\n",
    "    'Hertha BSC' : 6,\n",
    "    'Sport-Club Freiburg' : 7,\n",
    "    '1. FC Köln' : 5,\n",
    "    'SV Darmstadt 98' : 18,\n",
    "    'Hamburger SV' : 14,\n",
    "    'FC Ingolstadt 04' : 17,\n",
    "    'FC Augsburg' : 13,\n",
    "    'VfL Wolfsburg' : 16,\n",
    "    'TSG 1899 Hoffenheim' : 4,\n",
    "    'RB Leipzig' : 2,\n",
    "    'FC Schalke 04' : 10,\n",
    "    'Eintracht Frankfurt' : 11\n",
    "}\n",
    "\n",
    "Quality_dict['Goal_difference'] = {\n",
    "    'FC Bayern München' : 67, \n",
    "    'SV Werder Bremen' : -3,\n",
    "    'Borussia Dortmund' : 32,\n",
    "    '1. FSV Mainz 05': -11,\n",
    "    'Borussia Mönchengladbach' : -4,\n",
    "    'Bayer 04 Leverkusen' : -2,\n",
    "    'Hertha BSC' : -4,\n",
    "    'Sport-Club Freiburg' : -18,\n",
    "    '1. FC Köln' : 9,\n",
    "    'SV Darmstadt 98' : -35,\n",
    "    'Hamburger SV' : -28,\n",
    "    'FC Ingolstadt 04' : -21,\n",
    "    'FC Augsburg' : -16,\n",
    "    'VfL Wolfsburg' : -18,\n",
    "    'TSG 1899 Hoffenheim' : 27,\n",
    "    'RB Leipzig' : 27,\n",
    "    'FC Schalke 04' : 5,\n",
    "    'Eintracht Frankfurt' : -7\n",
    "}\n",
    "\n",
    "with open('Pickles/Quality_dict.pkl', 'wb') as dic:\n",
    "    pickle.dump(Quality_dict, dic)\n",
    "Quality_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98449ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/team_Success_Score_game_av.pkl', 'rb') as cdict:\n",
    "    team_Success_Score_game_av = pickle.load(cdict)\n",
    "    \n",
    "with open('Output/team_Success_Score_game.pkl', 'rb') as cdict:\n",
    "    team_Success_Score_game = pickle.load(cdict)\n",
    "    \n",
    "with open('Games_Included.pkl', 'rb') as l:\n",
    "    games_included = pickle.load(l)\n",
    "    \n",
    "GO = pd.read_csv('Output/GameOverview3.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table for mixed model\n",
    "\n",
    "# game\n",
    "# team (--> TQ)\n",
    "# opponent --> TQ\n",
    "# home or away (dummy)\n",
    "# possession percentage\n",
    "# match outcome (categorical)\n",
    "# match outcome (difference)\n",
    "# average Success Score (ASS) 16m100s for that game\n",
    "# TQ_points, ranking & goal difference\n",
    "# OQ see above\n",
    "# ASS 16m300s\n",
    "# ASS 16m500s\n",
    "# ASS 30m100s\n",
    "# ASS 30m300s\n",
    "# ASS 30m500s\n",
    "\n",
    "# outcome dictionary to match team outcome to opponents logical outcome\n",
    "outcomes = {1: -1,\n",
    "            0: 0,\n",
    "           -1: 1}\n",
    "\n",
    "game_column = []\n",
    "team_column = []\n",
    "opponent_column = []\n",
    "location_column = []\n",
    "possession_column = []\n",
    "outcome_cat_column = []\n",
    "outcome_num_column = []\n",
    "TQ_r = []\n",
    "TQ_p = []\n",
    "TQ_gd = []\n",
    "OQ_r = []\n",
    "OQ_p = []\n",
    "OQ_gd = []\n",
    "ASS_16m_100s = []\n",
    "ASS_16m_300s = []\n",
    "ASS_16m_500s = []\n",
    "ASS_30m_100s = []\n",
    "ASS_30m_300s = []\n",
    "ASS_30m_500s = []\n",
    "ASS_16m_100s_diff = []\n",
    "ASS_16m_300s_diff = []\n",
    "ASS_16m_500s_diff = []\n",
    "ASS_30m_100s_diff = []\n",
    "ASS_30m_300s_diff = []\n",
    "ASS_30m_500s_diff = []\n",
    "ASS_16m_100s_diff_per = []\n",
    "ASS_16m_300s_diff_per = []\n",
    "ASS_16m_500s_diff_per = []\n",
    "ASS_30m_100s_diff_per = []\n",
    "ASS_30m_300s_diff_per = []\n",
    "ASS_30m_500s_diff_per = []\n",
    "\n",
    "for game in games_included:\n",
    "    game_column.append(game)\n",
    "    game_column.append(game)\n",
    "    location_column.append(1) # 1 = home\n",
    "    location_column.append(0) # 0 = away\n",
    "    Home = GO.Home[GO.MI_Name == game].to_list()[0] # Home team = Team in 1 and opponent in 2\n",
    "    Away = GO.Away[GO.MI_Name == game].to_list()[0] # Away team = Team in 2 and opponent in 1\n",
    "    team_column.append(Home)\n",
    "    team_column.append(Away)\n",
    "    possession_column.append(GO.Pos_Home[GO.MI_Name == game].to_list()[0])\n",
    "    possession_column.append(GO.Pos_Away[GO.MI_Name == game].to_list()[0])\n",
    "    opponent_column.append(Away)\n",
    "    opponent_column.append(Home)\n",
    "    \n",
    "    # determine categorical outcome (W, D, L)\n",
    "    goals_scored = GO.Final_Score[GO.MI_Name == game].to_list()[0].split(':')\n",
    "    if int(goals_scored[0]) >  int(goals_scored[1]):\n",
    "        Home_Outcome = 1\n",
    "    elif  int(goals_scored[0]) <  int(goals_scored[1]):\n",
    "        Home_Outcome = -1\n",
    "    else:\n",
    "        Home_Outcome = 0\n",
    "    Away_Outcome = outcomes[Home_Outcome] # match opponents outcome \n",
    "    \n",
    "    outcome_cat_column.append(Home_Outcome)\n",
    "    outcome_cat_column.append(Away_Outcome)\n",
    "    \n",
    "    # determine difference in goals scored\n",
    "    Home_Outcome = int(goals_scored[0]) - int(goals_scored[1])\n",
    "    Away_Outcome = Home_Outcome *-1\n",
    "    \n",
    "    outcome_num_column.append(Home_Outcome)\n",
    "    outcome_num_column.append(Away_Outcome)\n",
    "    \n",
    "    # TQ = team quality\n",
    "    TQ_r.append(Quality_dict['Ranking'][Home])\n",
    "    TQ_p.append(Quality_dict['Points'][Home])\n",
    "    TQ_gd.append(Quality_dict['Goal_difference'][Home])\n",
    "    TQ_r.append(Quality_dict['Ranking'][Away])\n",
    "    TQ_p.append(Quality_dict['Points'][Away])\n",
    "    TQ_gd.append(Quality_dict['Goal_difference'][Away])\n",
    "    \n",
    "    # OQ = opponent team quality\n",
    "    OQ_r.append(Quality_dict['Ranking'][Away])\n",
    "    OQ_p.append(Quality_dict['Points'][Away])\n",
    "    OQ_gd.append(Quality_dict['Goal_difference'][Away])\n",
    "    OQ_r.append(Quality_dict['Ranking'][Home])\n",
    "    OQ_p.append(Quality_dict['Points'][Home])\n",
    "    OQ_gd.append(Quality_dict['Goal_difference'][Home])\n",
    "    \n",
    "    # success scores for each game\n",
    "    SSH = team_Success_Score_game_av['16m_100s'][Home][game]\n",
    "    SSA = team_Success_Score_game_av['16m_100s'][Away][game]\n",
    "    ASS_16m_100s.append(SSH)\n",
    "    ASS_16m_100s.append(SSA)\n",
    "    ASS_16m_100s_diff.append(SSH - SSA)\n",
    "    ASS_16m_100s_diff.append(SSA - SSH)\n",
    "    \n",
    "    \n",
    "    SSH = team_Success_Score_game_av['16m_300s'][Home][game]\n",
    "    SSA = team_Success_Score_game_av['16m_300s'][Away][game]\n",
    "    ASS_16m_300s.append(SSH)\n",
    "    ASS_16m_300s.append(SSA)\n",
    "    ASS_16m_300s_diff.append(SSH - SSA)\n",
    "    ASS_16m_300s_diff.append(SSA - SSH)\n",
    "    \n",
    "    SSH = team_Success_Score_game_av['16m_500s'][Home][game]\n",
    "    SSA = team_Success_Score_game_av['16m_500s'][Away][game]\n",
    "    ASS_16m_500s.append(SSH)\n",
    "    ASS_16m_500s.append(SSA)    \n",
    "    ASS_16m_500s_diff.append(SSH - SSA)\n",
    "    ASS_16m_500s_diff.append(SSA - SSH)\n",
    "    \n",
    "    \n",
    "    SSH = team_Success_Score_game_av['30m_100s'][Home][game]\n",
    "    SSA = team_Success_Score_game_av['30m_100s'][Away][game]\n",
    "    ASS_30m_100s.append(SSH)\n",
    "    ASS_30m_100s.append(SSA)\n",
    "    ASS_30m_100s_diff.append(SSH - SSA)\n",
    "    ASS_30m_100s_diff.append(SSA - SSH)\n",
    "    \n",
    "    SSH = team_Success_Score_game_av['30m_300s'][Home][game]\n",
    "    SSA = team_Success_Score_game_av['30m_100s'][Away][game]\n",
    "    ASS_30m_300s.append(SSH)\n",
    "    ASS_30m_300s.append(SSA)\n",
    "    ASS_30m_300s_diff.append(SSH - SSA)\n",
    "    ASS_30m_300s_diff.append(SSA - SSH)\n",
    "    \n",
    "    SSH = team_Success_Score_game_av['30m_500s'][Home][game]\n",
    "    SSA = team_Success_Score_game_av['30m_500s'][Away][game]\n",
    "    ASS_30m_500s.append(SSH)\n",
    "    ASS_30m_500s.append(SSA)\n",
    "    ASS_30m_500s_diff.append(SSH - SSA)\n",
    "    ASS_30m_500s_diff.append(SSA - SSH)\n",
    "    \n",
    "    \n",
    "MLM = pd.DataFrame(zip(game_column, team_column, location_column, outcome_cat_column, outcome_num_column,possession_column,\n",
    "                       TQ_r, TQ_p, TQ_gd, OQ_r, OQ_p, OQ_gd,\n",
    "                       ASS_16m_100s, ASS_16m_300s, ASS_16m_500s, ASS_30m_100s, ASS_30m_300s, ASS_30m_500s,\n",
    "                      ASS_16m_100s_diff, ASS_16m_300s_diff, ASS_16m_500s_diff, ASS_30m_100s_diff, ASS_30m_300s_diff, ASS_30m_500s_diff),\n",
    "                  columns = ['Game', 'Team', 'Location', 'Outcome_cat', 'Outcome_num', 'possession',\n",
    "                             'TQ_r', 'TQ_p', 'TQ_gd', 'OQ_r', 'OQ_p', 'OQ_gd',\n",
    "                            'ASS_16m_100s', 'ASS_16m_300s', 'ASS_16m_500s', 'ASS_30m_100s', 'ASS_30m_300s', 'ASS_30m_500s',\n",
    "                            'ASS_16m_100s_diff', 'ASS_16m_300s_diff', 'ASS_16m_500s_diff', 'ASS_30m_100s_diff', 'ASS_30m_300s_diff', 'ASS_30m_500s_diff'])\n",
    "\n",
    "MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLM.to_csv('Results/MLM_data_e100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae90afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "MLM = pd.read_csv('Results/MLM_data_e100.csv')\n",
    "MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21298ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from statistics import mean\n",
    "from scipy.stats import iqr\n",
    "scores = MLM.columns.to_list()[-6:]\n",
    "\n",
    "N = []\n",
    "mean = []\n",
    "median = []\n",
    "sd = []\n",
    "P25 = []\n",
    "P75 = []\n",
    "IQR = []\n",
    "Min = []\n",
    "Max = []\n",
    "\n",
    "for s in scores:\n",
    "    data = MLM[s][MLM[s] > 0]\n",
    "    N.append(len(data))\n",
    "    mean.append(data.mean())\n",
    "    median.append(data.median())\n",
    "    sd.append(data.std())\n",
    "    Min.append(min(data))\n",
    "    Max.append(max(data))\n",
    "    P25.append(np.percentile(data, 25))\n",
    "    P75.append(np.percentile(data, 75))\n",
    "    IQR.append(iqr(data))\n",
    "    \n",
    "\n",
    "game_desc = pd.DataFrame(zip(N, mean, median, sd, Min, Max, P25, P75, IQR),\n",
    "                         columns=['N', 'Mean', 'Median', 'SD', 'Min', 'Max', 'P25', 'P75', 'IQR'],\n",
    "                        index = scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f0940",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_desc.to_csv('Results/game_desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd69793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0965497",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, sharey=False, tight_layout=True)\n",
    "\n",
    "for s, score in enumerate(scores):\n",
    "    y = 0 if s <= 2 else 1\n",
    "    x = s if y == 0 else s-3\n",
    "    # print(s, x, y)\n",
    "    lim =  10 if s <= 2 else 20\n",
    "    stepsize =  lim/2\n",
    "    axs[y,x].hist(MLM[score][MLM[score] > 0], density = True, color = '#07607e',\n",
    "                  bins = np.arange(0, max(MLM[score]), 0.5))\n",
    "    axs[y,x].set_xlim([0, lim])\n",
    "    axs[y,x].xaxis.set_ticks(np.arange(0, lim+1, stepsize))\n",
    "    axs[y,x].axvline(x = game_desc.P25[s], ymin = 0, ymax= 0.98, color = '#f13b38', linestyle = 'dashed')\n",
    "    axs[y,x].axvline(x = game_desc.P75[s], ymin = 0, ymax= 0.98, color = '#f13b38', linestyle = 'dashed')\n",
    "\n",
    "    #axs[y,x].spines['top'].set_visible(False)\n",
    "    #axs[y,x].spines['right'].set_visible(False)\n",
    "    axs[y,x].spines['top'].set_color('#B1B1B1')\n",
    "    axs[y,x].spines['right'].set_color('#B1B1B1')\n",
    "    axs[y,x].spines['left'].set_color('#B1B1B1')\n",
    "    axs[y,x].spines['bottom'].set_color('#B1B1B1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.pyplot.close(fig = 'all')\n",
    "\n",
    "groupingvar1 = ['16m', '30m']\n",
    "groupingvar2 = ['100s', '300s', '500s']\n",
    "colors = ['#5D8DAF', '#8daf5d']\n",
    "# colors = ['#5D8DAF', '#f24e4b']\n",
    "\n",
    "with plt.style.context('C:/Users/DavidB/PythonProjects/Style/StyleScientific.mplstyle'):\n",
    "    fig, axes = plt.subplots(2,3, sharey=False, layout='constrained')\n",
    "    for s, score in enumerate(scores):\n",
    "        data = MLM[score][MLM[score] > 0]\n",
    "        y = 0 if s <= 2 else 1\n",
    "        x = s if y == 0 else s-3       \n",
    "        limx =  10 if s <= 2 else 20\n",
    "        stepsizex =  limx/2\n",
    "        \n",
    "        limy = 0.5 if s <= 2 else 0.2\n",
    "        stepsizey = limy/5\n",
    "        \n",
    "        axes[y, x].hist(data, density = True, color = colors[y], bins = np.arange(0, max(MLM[score]), 0.5),\n",
    "                            label = ''.join([groupingvar1[y], groupingvar2[x]]))\n",
    "        axes[y,x].axvline(x = game_desc.P25[s], ymin = 0, ymax= 0.98, color = '#f13b38', linestyle = 'dashed')\n",
    "        axes[y,x].axvline(x = game_desc.P75[s], ymin = 0, ymax= 0.98, color = '#f13b38', linestyle = 'dashed')\n",
    "        axes[y,x].set_xlim([0, limx])\n",
    "        axes[y,x].xaxis.set_ticks(np.arange(0, limx+1, stepsizex))\n",
    "        axes[y,x].set_ylim([0, limy])\n",
    "        axes[y,x].yaxis.set_ticks(np.arange(0, limy+0.01, stepsizey))\n",
    "        axes[y,x].tick_params(axis='both', labelsize = 8)\n",
    "        \n",
    "        if x == 0:\n",
    "            axes[y,x].set_ylabel(groupingvar1[y], fontsize = 9)\n",
    "        if y == 1:\n",
    "            axes[y,x].set_xlabel(groupingvar2[x], fontsize = 9)\n",
    "        \n",
    "    fig.supxlabel('Success-Score', size =10)\n",
    "    fig.supylabel('Density', size = 10)\n",
    "    #fig.legend(title= 'Success-Score', loc='outside right upper', fontsize = 8, title_fontsize = 9)\n",
    "\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e9851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "floodlight_env",
   "language": "python",
   "name": "floodlight_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
