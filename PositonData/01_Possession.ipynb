{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb155f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_urls = []\n",
    "\n",
    "# create a base URL\n",
    "base_url = 'https://fbref.com'\n",
    "schedule_url = 'https://fbref.com/en/comps/20/2016-2017/schedule/2016-2017-Bundesliga-Scores-and-Fixtures'\n",
    "\n",
    "\n",
    "# use request to get URL\n",
    "schedule_page = requests.get(schedule_url)\n",
    "\n",
    "\n",
    "# parse URL / content of the page; need to find the url to all matches\n",
    "soup = BeautifulSoup(schedule_page.content, 'html.parser')\n",
    "results = soup.find(id=\"sched_all\")\n",
    "matches = results.find_all(\"td\", class_=\"center\")\n",
    "\n",
    "# go trough matches and access the url and combine it with the base url for a working url to the match\n",
    "for match in matches:\n",
    "    links = match.find_all(\"a\")\n",
    "    for link in links:\n",
    "        url = base_url + link[\"href\"]\n",
    "        match_urls.append(url)\n",
    "\n",
    "        \n",
    "with open('MatchURLs', 'wb') as fp:\n",
    "        pickle.dump(match_urls, fp)        \n",
    "        \n",
    "        \n",
    "#with open('MatchURLs', 'rb') as fp:\n",
    "#        match_urls = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "Home = []\n",
    "Away = []\n",
    "home_pos = []\n",
    "away_pos = []\n",
    "\n",
    "for match_url in match_urls:\n",
    "    time.sleep(12)\n",
    "    text = []\n",
    "    percentages = []\n",
    "\n",
    "\n",
    "    # use request to get URL\n",
    "    match_page = requests.get(match_url)\n",
    "\n",
    "    # parse URL / content of the page\n",
    "    soup = BeautifulSoup(match_page.content, 'html.parser')\n",
    "\n",
    "    results = soup.find(id=\"content\")\n",
    "    scoreboxes = results.find_all(\"div\", class_=\"scorebox\")\n",
    "    for scorebox in scoreboxes:\n",
    "        ass = scorebox.find_all(\"a\")\n",
    "        for a in ass:\n",
    "            text.append(a.text)\n",
    "\n",
    "    Home.append(text[0])\n",
    "    Away.append(text[4])\n",
    "    \n",
    "    results = soup.find(id=\"team_stats\")\n",
    "    tables = results.find_all('table')\n",
    "    for table in tables:\n",
    "        trs = table.find_all('tr')\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td')\n",
    "            for td in tds:\n",
    "                s = td.find_all('strong')\n",
    "                percentages.append(str(s).replace('[<strong>', '').replace('%</strong>]', ''))\n",
    "\n",
    "    home_pos.append(percentages[0])\n",
    "    away_pos.append(percentages[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45143308",
   "metadata": {},
   "outputs": [],
   "source": [
    "possession_overview = pd.DataFrame(list(zip(Home, Away, home_pos, away_pos)),\n",
    "                                           columns = ['Home', 'Away', 'Pos_Home', 'Pos_Away'])\n",
    "possession_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f38a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "possession_overview = possession_overview[:306]\n",
    "possession_overview.to_csv('Output/PossessionOverview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match names\n",
    "\n",
    "game_overview2= pd.read_csv('Output/GameOverview2.csv')\n",
    "game_overview2.Home.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b278c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "possession_overview = pd.read_csv('Output/PossessionOverview.csv')\n",
    "possession_overview = possession_overview.iloc[:, 1:]\n",
    "possession_overview.Home.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "possession_overview.replace(possession_overview.Home.unique(), ['FC Bayern München', 'Borussia Dortmund', 'Hamburger SV', \n",
    "                                                               'Eintracht Frankfurt', '1. FC Köln', 'FC Augsburg', \n",
    "                                                               'Borussia Mönchengladbach', 'Hertha BSC', 'TSG 1899 Hoffenheim',\n",
    "                                                               'FC Schalke 04', 'Bayer 04 Leverkusen', 'Sport-Club Freiburg',\n",
    "                                                               'VfL Wolfsburg', 'FC Ingolstadt 04', 'SV Darmstadt 98',\n",
    "                                                               'RB Leipzig', 'SV Werder Bremen', '1. FSV Mainz 05'],\n",
    "                            inplace= True)\n",
    "possession_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b61358",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_overview = pd.merge(game_overview2, possession_overview, on = ['Home', 'Away'], how = 'inner')\n",
    "new_overview = new_overview.iloc[:,1:]\n",
    "\n",
    "new_overview.to_csv('Output/GameOverview3.csv')\n",
    "new_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b0205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "floodlight_env",
   "language": "python",
   "name": "floodlight_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
